from .image_enhancer import AdvancedImageEnhancer
from .face_detector import MultiFaceDetector
from .face_recognizer import FaceRecognizer
from config import settings
from typing import Dict, Any
from core.temp_file_manager import temp_file_context
from core.utils import compute_histogram_similarity, compute_structural_similarity, cosine_distance
import time
import logging
import cv2
import uuid
import shutil
import numpy as np
from PIL import Image, ExifTags
import os

logger = logging.getLogger(__name__)
UPLOADS_DIR = settings.UPLOADS_DIR

try:
    import insightface
    from insightface.app import FaceAnalysis
    INSIGHTFACE_AVAILABLE = True
except ImportError:
    INSIGHTFACE_AVAILABLE = False

class SenseFaceVerifier:
    """üéØ BALANCED: Advanced face verification with rotation handling + false positive prevention"""
    
    def __init__(self):
        self.face_detector = MultiFaceDetector()
        self.face_recognizer = FaceRecognizer()
        self.image_enhancer = AdvancedImageEnhancer(settings.MODELS_DIR)
        
        # InsightFace app for combined detection and recognition if available
        self.insightface_app = None
        if INSIGHTFACE_AVAILABLE:
            try:
                self.insightface_app = FaceAnalysis(name='buffalo_l')
                self.insightface_app.prepare(ctx_id=0, det_size=(640, 640))
                logger.info("Using InsightFace for combined detection and recognition")
            except Exception as e:
                logger.warning(f"Could not initialize InsightFace app: {e}")

        # üéØ BALANCED THRESHOLDS - Prevent false positives while handling rotation
        self.detection_thresholds = {
            "normal": 0.35,           # 35% for normal images (reasonable)
            "rotated_90": 0.25,       # 25% for 90¬∞ rotations (slightly lower)
            "arbitrary": 0.20,        # 20% for arbitrary angles (lowest acceptable)
            "insightface_normal": 0.6, # 60% for InsightFace normal
            "insightface_rotated": 0.4, # 40% for InsightFace rotated
            "insightface_arbitrary": 0.3, # 30% for InsightFace arbitrary
            "geometric_min": 0.15     # 15% absolute minimum for geometric fallback
        }

    def correct_image_orientation(self, image_path):
        """
        FAST: Correct image orientation using EXIF data only
        Performance: ~0.1 seconds, handles 90% of rotation issues
        """
        try:
            # Quick EXIF check without loading full image
            with Image.open(image_path) as img:
                exif = img.getexif()
                if exif and 274 in exif:  # 274 is EXIF orientation tag
                    orientation = exif[274]
                    
                    # Only process if rotation is actually needed
                    if orientation in [3, 6, 8]:
                        img = img.copy()  # Load the image now
                        if orientation == 3:
                            img = img.rotate(180, expand=True)
                        elif orientation == 6:
                            img = img.rotate(270, expand=True)
                        elif orientation == 8:
                            img = img.rotate(90, expand=True)
                        
                        # Convert to OpenCV format
                        return cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            
            # No rotation needed, read normally (fastest path)
            return cv2.imread(image_path)
            
        except Exception:
            # Fallback to normal OpenCV read
            return cv2.imread(image_path)

    def rotate_image_ultra_safe(self, image, angle):
        """
        ULTRA SAFE: Rotate image with maximum padding to prevent any cropping
        """
        try:
            if abs(angle) < 0.1:  # No rotation needed
                return image
            
            h, w = image.shape[:2]
            
            # Use maximum possible dimensions to prevent any cropping
            diagonal = int(np.sqrt(h*h + w*w)) + 200  # Extra large padding
            center = (diagonal // 2, diagonal // 2)
            
            # Create large canvas and place image in center
            large_canvas = np.full((diagonal, diagonal, 3), 255, dtype=np.uint8)
            y_offset = (diagonal - h) // 2
            x_offset = (diagonal - w) // 2
            large_canvas[y_offset:y_offset+h, x_offset:x_offset+w] = image
            
            # Now rotate the large canvas
            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            rotated = cv2.warpAffine(large_canvas, rotation_matrix, (diagonal, diagonal), 
                                   borderMode=cv2.BORDER_CONSTANT, 
                                   borderValue=(255, 255, 255))
            
            return rotated
            
        except Exception as e:
            logger.error(f"Ultra safe rotation error: {e}")
            return image

    def assess_image_quality(self, img):
        """
        üîç QUALITY ASSESSMENT: Basic image quality check to prevent false positives
        """
        try:
            if img is None or img.size == 0:
                return {"overall_quality": 0.0, "contrast": 0.0, "brightness": 0.0}
            
            # Convert to grayscale for analysis
            if len(img.shape) == 3:
                gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            else:
                gray = img
            
            # Basic quality metrics
            contrast = np.std(gray)  # Standard deviation as contrast measure
            brightness = np.mean(gray)  # Mean brightness
            
            # Quality scoring
            contrast_score = min(contrast / 50.0, 1.0)  # Normalize contrast
            brightness_score = 1.0 - abs(brightness - 128) / 128.0  # Optimal around 128
            brightness_score = max(0.0, brightness_score)
            
            overall_quality = (contrast_score * 0.6 + brightness_score * 0.4)
            
            return {
                "overall_quality": float(overall_quality),
                "contrast": float(contrast),
                "brightness": float(brightness)
            }
            
        except Exception as e:
            logger.error(f"Quality assessment error: {e}")
            return {"overall_quality": 0.5, "contrast": 25.0, "brightness": 128.0}

    def smart_face_detection_with_rotation(self, img, app_or_detector=None):
        """
        üéØ BALANCED: Handle rotation with quality controls to prevent false positives
        """
        logger.info("üéØ Starting BALANCED rotation detection with quality controls...")
        
        # STEP 1: Try normal detection with REASONABLE thresholds
        logger.info("Step 1: Testing 0¬∞ rotation with quality standards...")
        if app_or_detector is None:
            temp_path = "/tmp/temp_detection.jpg"
            try:
                cv2.imwrite(temp_path, img)
                face = self.face_detector.get_best_face(temp_path)
                
                if face and face.get("confidence", 0) > self.detection_thresholds["normal"]:
                    logger.info(f"‚úÖ SUCCESS at 0¬∞ - Confidence: {face.get('confidence', 0):.4f}")
                    return img, 0, face
                else:
                    conf = face.get('confidence', 0) if face else 0
                    logger.info(f"‚ùå 0¬∞ failed (confidence: {conf:.4f})")
            except Exception as e:
                logger.error(f"0¬∞ detection error: {e}")
        else:
            try:
                faces = app_or_detector.get(img)
                if faces and len(faces) > 0:
                    face = faces[0]
                    det_score = getattr(face, 'det_score', 0.0)
                    
                    if det_score > self.detection_thresholds["insightface_normal"]:
                        logger.info(f"‚úÖ SUCCESS at 0¬∞ with InsightFace - Score: {det_score:.4f}")
                        return img, 0, faces
                    else:
                        logger.info(f"‚ùå 0¬∞ InsightFace failed (score: {det_score:.4f})")
            except Exception as e:
                logger.error(f"InsightFace 0¬∞ error: {e}")
        
        # STEP 2: Try standard rotations (90¬∞, 180¬∞, 270¬∞)
        logger.info("Step 2: Testing standard rotations with reasonable thresholds...")
        
        standard_angles = [90, 180, 270]
        
        for angle in standard_angles:
            try:
                logger.info(f"  üîÑ Testing {angle}¬∞ rotation...")
                
                rotated_img = self.rotate_image_ultra_safe(img, angle)
                
                if app_or_detector is None:
                    temp_path = "/tmp/temp_detection.jpg"
                    cv2.imwrite(temp_path, rotated_img)
                    face = self.face_detector.get_best_face(temp_path)
                    
                    if face and face.get("confidence", 0) > self.detection_thresholds["rotated_90"]:
                        confidence = face.get('confidence', 0)
                        logger.info(f"üéâ SUCCESS at {angle}¬∞! Confidence: {confidence:.4f}")
                        return rotated_img, angle, face
                else:
                    faces = app_or_detector.get(rotated_img)
                    if faces and len(faces) > 0:
                        face = faces[0]
                        det_score = getattr(face, 'det_score', 0.0)
                        
                        if det_score > self.detection_thresholds["insightface_rotated"]:
                            logger.info(f"üéâ SUCCESS at {angle}¬∞ with InsightFace! Score: {det_score:.4f}")
                            return rotated_img, angle, faces
            except Exception as e:
                logger.error(f"Error at {angle}¬∞: {e}")
                continue
        
        # STEP 3: Try arbitrary angles with STRICTER quality control
        logger.info("Step 3: Testing arbitrary angles with strict quality control...")
        
        # Focused angle list - most common document rotations
        arbitrary_angles = [
            # 45-degree family (most common arbitrary rotations)
            45, 135, 225, 315,
            # 30-degree family
            30, 150, 210, 330,
            # Fine angles around 45¬∞ (for rotated ID cards)
            35, 40, 50, 55,
            # Other common angles
            15, 60, 120, 240, 300
        ]
        
        best_result = None
        best_score = 0.0
        
        for angle in arbitrary_angles:
            try:
                logger.debug(f"  Testing arbitrary angle {angle}¬∞...")
                
                rotated_img = self.rotate_image_ultra_safe(img, angle)
                
                if app_or_detector is None:
                    temp_path = "/tmp/temp_detection.jpg"
                    cv2.imwrite(temp_path, rotated_img)
                    face = self.face_detector.get_best_face(temp_path)
                    
                    if face:
                        confidence = face.get("confidence", 0)
                        
                        if confidence > self.detection_thresholds["arbitrary"]:
                            if confidence > best_score:
                                best_result = (rotated_img, angle, face)
                                best_score = confidence
                            
                            # If confidence is good enough, return immediately
                            if confidence > 0.4:  # Strong confidence
                                logger.info(f"üéâ HIGH CONFIDENCE at {angle}¬∞! Confidence: {confidence:.4f}")
                                return rotated_img, angle, face
                else:
                    faces = app_or_detector.get(rotated_img)
                    if faces and len(faces) > 0:
                        face = faces[0]
                        det_score = getattr(face, 'det_score', 0.0)
                        
                        if det_score > self.detection_thresholds["insightface_arbitrary"]:
                            if det_score > best_score:
                                best_result = (rotated_img, angle, faces)
                                best_score = det_score
                            
                            # If score is good enough, return immediately
                            if det_score > 0.6:  # Strong confidence
                                logger.info(f"üéâ HIGH CONFIDENCE at {angle}¬∞ with InsightFace! Score: {det_score:.4f}")
                                return rotated_img, angle, faces
            
            except Exception as e:
                logger.debug(f"Error at arbitrary angle {angle}¬∞: {e}")
                continue
        
        # STEP 4: Return best result if found
        if best_result is not None:
            rotated_img, angle, face_or_faces = best_result
            logger.info(f"üèÜ BEST arbitrary angle result: {angle}¬∞ with score: {best_score:.4f}")
            return best_result
        
        # STEP 5: CONTROLLED fallback - Only for landscape images (ID cards) with quality checks
        h, w = img.shape[:2]
        
        if w > h * 1.3:  # Strong landscape ratio (likely ID card)
            logger.warning("‚ö†Ô∏è Trying CONTROLLED geometric fallback for ID card...")
            
            # Assess image quality first
            quality = self.assess_image_quality(img)
            
            if quality["overall_quality"] < 0.3:  # Poor quality image
                logger.warning(f"‚ö†Ô∏è Image quality too poor ({quality['overall_quality']:.3f}) - REJECTING geometric fallback")
                return img, 0, None
            
            # Only try the most likely face region for ID cards
            face_region = {
                "bbox": [int(w*0.6), int(h*0.1), int(w*0.9), int(h*0.6)],  # Right side face area
                "confidence": self.detection_thresholds["geometric_min"],  # Minimum acceptable confidence
                "type": "controlled_id_fallback",
                "quality": quality
            }
            
            # Extract the region and do basic validation
            x1, y1, x2, y2 = face_region["bbox"]
            x1 = max(0, min(x1, w-1))
            y1 = max(0, min(y1, h-1))
            x2 = max(x1+1, min(x2, w))
            y2 = max(y1+1, min(y2, h))
            
            region_img = img[y1:y2, x1:x2]
            
            # Basic quality check on the region
            if region_img.size > 0:
                region_quality = self.assess_image_quality(region_img)
                
                # Check if region has reasonable quality
                if region_quality["contrast"] > 20 and region_quality["overall_quality"] > 0.25:
                    logger.warning(f"üîß CONTROLLED fallback accepted - Region quality: {region_quality['overall_quality']:.3f}")
                    face_region["bbox"] = [x1, y1, x2, y2]
                    face_region["region_quality"] = region_quality
                    return img, 0, face_region
                else:
                    logger.warning(f"‚ö†Ô∏è Region quality insufficient ({region_quality['overall_quality']:.3f}) - REJECTING")
        
        # STEP 6: FAIL gracefully - Don't force success
        logger.error("‚ùå All detection methods failed with quality controls - REJECTING to prevent false positive")
        return img, 0, None

    def verify_with_insightface(self, img1_path: str, img2_path: str, threshold: float = 0.4) -> Dict[str, Any]:
        """üéØ BALANCED: InsightFace verification with quality controls and false positive prevention"""
        try:
            logger.info("üéØ Starting BALANCED InsightFace verification...")
            
            # Step 1: EXIF orientation correction
            img1 = self.correct_image_orientation(img1_path)
            img2 = self.correct_image_orientation(img2_path)
            
            if img1 is None or img2 is None:
                return {"verified": False, "error": "Could not read images"}
            
            # Step 2: BALANCED rotation detection
            logger.info("üîÑ Processing ID card with balanced detection...")
            img1_final, rotation1, faces1 = self.smart_face_detection_with_rotation(img1, self.insightface_app)
            
            logger.info("üîÑ Processing selfie with balanced detection...")
            img2_final, rotation2, faces2 = self.smart_face_detection_with_rotation(img2, self.insightface_app)
            
            logger.info(f"üéØ Rotation results - ID: {rotation1}¬∞, Photo: {rotation2}¬∞")
            
            # QUALITY CHECK: Reject if either face detection failed
            if not faces1 or not faces2:
                return {
                    "verified": False, 
                    "error": "Face detection failed - insufficient quality for verification", 
                    "rotations_applied": (rotation1, rotation2),
                    "mode": "balanced_insightface_quality_rejected"
                }
            
            # Step 3: Extract faces and validate
            face1 = faces1[0]
            face2 = faces2[0]
            
            # QUALITY CHECK: Identify geometric fallback usage
            is_geometric1 = isinstance(face1, dict) and face1.get("type", "").startswith("controlled")
            is_geometric2 = isinstance(face2, dict) and face2.get("type", "").startswith("controlled")
            
            if is_geometric1 and is_geometric2:
                # Both are geometric - too risky for verification
                logger.warning("‚ö†Ô∏è Both faces are geometric fallback - REJECTING to prevent false positive")
                return {
                    "verified": False,
                    "error": "Both faces detected using geometric fallback - insufficient quality",
                    "rotations_applied": (rotation1, rotation2),
                    "mode": "balanced_insightface_geometric_rejected"
                }
            elif is_geometric1 or is_geometric2:
                # One is geometric - use more strict threshold
                logger.warning("‚ö†Ô∏è One face is geometric fallback - using STRICT threshold")
                threshold = threshold * 0.75  # 25% stricter
            
            # Step 4: Perform verification
            if hasattr(face1, 'embedding') and hasattr(face2, 'embedding'):
                embedding1 = face1.embedding
                embedding2 = face2.embedding
                
                if embedding1 is not None and embedding2 is not None:
                    # Compute cosine similarity
                    sim = np.dot(embedding1, embedding2) / (
                        np.linalg.norm(embedding1) * np.linalg.norm(embedding2)
                    )
                    distance = float(1.0 - (sim + 1) / 2)
                    
                    # QUALITY-BASED threshold adjustment
                    det_score1 = getattr(face1, 'det_score', 1.0)
                    det_score2 = getattr(face2, 'det_score', 1.0)
                    avg_detection_quality = (det_score1 + det_score2) / 2
                    
                    # Adjust threshold based on detection quality
                    if avg_detection_quality > 0.8:
                        # High quality detection - can be slightly more lenient
                        adjusted_threshold = threshold * 1.05
                    elif avg_detection_quality < 0.5:
                        # Low quality detection - be more strict
                        adjusted_threshold = threshold * 0.85
                    else:
                        adjusted_threshold = threshold
                    
                    verified = bool(distance < adjusted_threshold)
                    
                    # Calculate confidence
                    if adjusted_threshold <= 0 or np.isnan(distance):
                        confidence = 0.0
                    else:
                        confidence = float(max(0, min(100, (1 - distance / adjusted_threshold) * 100)))
                    
                    # ADDITIONAL QUALITY CHECKS
                    # Reject very low confidence matches
                    if confidence < 15:  # Less than 15% confidence
                        logger.warning(f"‚ö†Ô∏è Very low confidence ({confidence:.1f}%) - REJECTING to prevent false positive")
                        verified = False
                    
                    # Extract bounding boxes
                    bbox1 = face1.bbox.astype(int) if hasattr(face1, 'bbox') else [0, 0, 0, 0]
                    bbox2 = face2.bbox.astype(int) if hasattr(face2, 'bbox') else [0, 0, 0, 0]
                    
                    result = {
                        "verified": verified,
                        "distance": float(distance),
                        "confidence": float(confidence),
                        "original_threshold": float(threshold),
                        "adjusted_threshold": float(adjusted_threshold),
                        "rotations_applied": (rotation1, rotation2),
                        "mode": "balanced_insightface",
                        "quality_control": {
                            "avg_detection_quality": float(avg_detection_quality),
                            "geometric_fallback_used": is_geometric1 or is_geometric2,
                            "quality_adjustment": "stricter" if avg_detection_quality < 0.5 else "standard" if avg_detection_quality < 0.8 else "lenient",
                            "min_confidence_met": confidence >= 15
                        },
                        "face_detection": {
                            "id_detected": True,
                            "id_bbox": bbox1.tolist() if hasattr(bbox1, 'tolist') else list(bbox1),
                            "id_confidence": float(det_score1),
                            "photo_detected": True,
                            "photo_bbox": bbox2.tolist() if hasattr(bbox2, 'tolist') else list(bbox2),
                            "photo_confidence": float(det_score2)
                        }
                    }
                    
                    logger.info(f"‚úÖ BALANCED verification complete - Verified: {verified}, "
                              f"Distance: {distance:.3f}, Adjusted Threshold: {adjusted_threshold:.3f}, "
                              f"Confidence: {confidence:.1f}%, Quality: {avg_detection_quality:.3f}")
                    return result
            
            # Fallback to geometric comparison with STRICT controls
            logger.warning("‚ö†Ô∏è Falling back to CONTROLLED geometric comparison")
            return self.verify_with_controlled_geometric_fallback(
                img1_final, img2_final, face1, face2, threshold, rotation1, rotation2
            )
            
        except Exception as e:
            logger.error(f"Balanced InsightFace verification error: {str(e)}")
            return {"verified": False, "error": f"Balanced verification error: {str(e)}"}

    def verify_with_controlled_geometric_fallback(self, img1, img2, face1, face2, threshold, rotation1, rotation2):
        """üîß CONTROLLED: Geometric fallback with STRICT quality controls"""
        try:
            logger.info("üîß Using CONTROLLED geometric fallback with strict quality controls...")
            
            # Extract face regions
            if isinstance(face1, dict):
                bbox1 = face1["bbox"]
                conf1 = face1.get("confidence", 0)
            else:
                bbox1 = getattr(face1, 'bbox', [0, 0, img1.shape[1], img1.shape[0]])
                conf1 = getattr(face1, 'det_score', 0)
                
            if isinstance(face2, dict):
                bbox2 = face2["bbox"]
                conf2 = face2.get("confidence", 0)
            else:
                bbox2 = getattr(face2, 'bbox', [0, 0, img2.shape[1], img2.shape[0]])
                conf2 = getattr(face2, 'det_score', 0)
            
            # QUALITY CHECK: Require minimum confidence for geometric fallback
            min_confidence = self.detection_thresholds["geometric_min"]
            if conf1 < min_confidence or conf2 < min_confidence:
                logger.warning(f"‚ö†Ô∏è Geometric fallback confidence too low ({conf1:.3f}, {conf2:.3f}) - REJECTING")
                return {
                    "verified": False,
                    "error": "Geometric fallback quality insufficient",
                    "mode": "controlled_geometric_rejected"
                }
            
            # Extract and validate face regions
            x1, y1, x2, y2 = bbox1
            face_img1 = img1[y1:y2, x1:x2]
            x1, y1, x2, y2 = bbox2
            face_img2 = img2[y1:y2, x1:x2]
            
            # QUALITY CHECK: Ensure regions are reasonable size
            min_face_size = 32
            if face_img1.shape[0] < min_face_size or face_img1.shape[1] < min_face_size or \
               face_img2.shape[0] < min_face_size or face_img2.shape[1] < min_face_size:
                logger.warning("‚ö†Ô∏è Face regions too small for reliable comparison - REJECTING")
                return {
                    "verified": False,
                    "error": "Face regions too small for geometric comparison",
                    "mode": "controlled_geometric_size_rejected"
                }
            
            # Resize for comparison
            face_img1 = cv2.resize(face_img1, (128, 128))
            face_img2 = cv2.resize(face_img2, (128, 128))
            
            # QUALITY CHECK: Basic image quality validation
            quality1 = self.assess_image_quality(face_img1)
            quality2 = self.assess_image_quality(face_img2)
            
            min_quality = 0.25
            if quality1["overall_quality"] < min_quality or quality2["overall_quality"] < min_quality:
                logger.warning(f"‚ö†Ô∏è Insufficient image quality ({quality1['overall_quality']:.3f}, {quality2['overall_quality']:.3f}) - REJECTING")
                return {
                    "verified": False,
                    "error": "Insufficient image quality for geometric comparison",
                    "mode": "controlled_geometric_quality_rejected"
                }
            
            # Enhanced histogram comparison
            hist1_rgb = cv2.calcHist([face_img1], [0, 1, 2], None, [32, 32, 32], [0, 256, 0, 256, 0, 256])
            hist2_rgb = cv2.calcHist([face_img2], [0, 1, 2], None, [32, 32, 32], [0, 256, 0, 256, 0, 256])
            cv2.normalize(hist1_rgb, hist1_rgb, 0, 1, cv2.NORM_MINMAX)
            cv2.normalize(hist2_rgb, hist2_rgb, 0, 1, cv2.NORM_MINMAX)
            
            similarity = cv2.compareHist(hist1_rgb, hist2_rgb, cv2.HISTCMP_CORREL)
            distance = 1.0 - similarity
            
            # STRICT threshold for geometric fallback
            geometric_threshold = threshold * 0.8  # 20% stricter than normal
            verified = bool(distance < geometric_threshold)
            
            # Conservative confidence calculation
            confidence = max(0, min(100, (1 - distance / geometric_threshold) * 100 * 0.75))  # Cap at 75%
            
            # FINAL QUALITY CHECK: Don't allow very high confidence for geometric
            if confidence > 70:  # Cap geometric confidence
                confidence = 70
                logger.warning("‚ö†Ô∏è Capping geometric fallback confidence at 70%")
            
            logger.info(f"üîß CONTROLLED geometric result - Distance: {distance:.3f}, "
                       f"Threshold: {geometric_threshold:.3f}, Verified: {verified}, "
                       f"Confidence: {confidence:.1f}%")
            
            return {
                "verified": verified,
                "distance": float(distance),
                "confidence": float(confidence),
                "original_threshold": float(threshold),
                "geometric_threshold": float(geometric_threshold),
                "rotations_applied": (rotation1, rotation2),
                "mode": "controlled_geometric_fallback",
                "method": "controlled_histogram_comparison",
                "quality_control": {
                    "min_confidence_met": True,
                    "face1_quality": quality1,
                    "face2_quality": quality2,
                    "face_sizes": [face_img1.shape[:2], face_img2.shape[:2]]
                }
            }
            
        except Exception as e:
            logger.error(f"Controlled geometric fallback error: {e}")
            return {
                "verified": False,
                "error": f"Controlled geometric fallback failed: {str(e)}",
                "mode": "controlled_geometric_fallback_failed"
            }
            
    def verify(self, img1_path: str, img2_path: str, threshold: float = 0.4, doc_type: str = "unknown") -> Dict[str, Any]:
        """üéØ BALANCED BANKING-GRADE: Face verification with rotation handling + false positive prevention"""
        start_time = time.time()
        
        try:
            logger.info(f"üéØ Starting BALANCED banking-grade verification for {doc_type}")
            
            # SECURITY: Input validation
            if not img1_path or not img2_path:
                return {"verified": False, "error": "Invalid image paths", "security_level": "FAILED"}
            
            # Use document-specific threshold from config
            doc_threshold = settings.DOCUMENT_THRESHOLDS.get(doc_type, threshold)
            logger.info(f"Using {doc_type} threshold: {doc_threshold}")
            
            # BALANCED PATH: Try InsightFace first with quality controls
            if INSIGHTFACE_AVAILABLE and self.insightface_app is not None:
                result = self.verify_with_insightface(img1_path, img2_path, doc_threshold)
                if "error" not in result:
                    # Secure image save
                    # img1_id, img2_id = str(uuid.uuid4())[:8], str(uuid.uuid4())[:8]
                    # shutil.copy(img1_path, UPLOADS_DIR / f"{img1_id}.jpg")
                    # shutil.copy(img2_path, UPLOADS_DIR / f"{img2_id}.jpg")
                    
                    
                    result.update({
                        "id_image": f"{img1_path}",
                        "photo_image": f"{img2_path}",
                        "threshold": float(doc_threshold),
                        "time": float(time.time() - start_time),
                        "doc_type": doc_type,
                        "security_level": "HIGH",
                        "method": "balanced_insightface_banking"
                    })
                    return result
            
            # BALANCED FALLBACK: Multi-layer verification with quality controls
            logger.info("üîß Using balanced fallback verification with quality controls...")
            
            img1_enhanced = self.image_enhancer.enhance_for_face_verification(img1_path, True)
            img2_enhanced = self.image_enhancer.enhance_for_face_verification(img2_path, False)
            
            # Read enhanced images with orientation correction
            img1 = self.correct_image_orientation(img1_enhanced)
            img2 = self.correct_image_orientation(img2_enhanced)
            
            if img1 is None or img2 is None:
                return {
                    "verified": False, "distance": 1.0, "threshold": float(doc_threshold),
                    "confidence": 0.0, "time": float(time.time() - start_time),
                    "error": "Could not read enhanced images", "doc_type": doc_type,
                    "security_level": "FAILED"
                }
            
            # BALANCED face detection with rotation and quality controls
            img1_final, rotation1, face1 = self.smart_face_detection_with_rotation(img1)
            img2_final, rotation2, face2 = self.smart_face_detection_with_rotation(img2)
            
            if not face1 or not face2:
                return {
                    "verified": False, "distance": 1.0, "threshold": float(doc_threshold),
                    "confidence": 0.0, "time": float(time.time() - start_time),
                    "error": "Balanced face detection failed - insufficient quality", "doc_type": doc_type,
                    "security_level": "FAILED",
                    "rotations_attempted": (rotation1, rotation2)
                }
            
            # QUALITY VALIDATION: Check face confidence
            min_face_confidence = self.detection_thresholds["geometric_min"]
            
            if face1["confidence"] < min_face_confidence or face2["confidence"] < min_face_confidence:
                logger.warning(f"‚ö†Ô∏è Face confidence too low - REJECTING to prevent false positive")
                return {
                    "verified": False, "distance": 1.0, "threshold": float(doc_threshold),
                    "confidence": 0.0, "time": float(time.time() - start_time),
                    "error": "Face detection confidence insufficient", "doc_type": doc_type,
                    "security_level": "FAILED",
                    "quality_control": {
                        "face1_confidence": float(face1["confidence"]),
                        "face2_confidence": float(face2["confidence"]),
                        "min_required": min_face_confidence
                    }
                }
            
            # Face extraction with validation (using the rotated images if needed)
            x1, y1, x2, y2 = face1["bbox"]
            face_img1 = img1_final[y1:y2, x1:x2]
            x1, y1, x2, y2 = face2["bbox"]
            face_img2 = img2_final[y1:y2, x1:x2]
            
            # QUALITY: Validate extracted faces
            if face_img1.size == 0 or face_img2.size == 0:
                logger.warning("‚ö†Ô∏è Empty face regions - REJECTING")
                return {
                    "verified": False, "distance": 1.0, "threshold": float(doc_threshold),
                    "confidence": 0.0, "time": float(time.time() - start_time),
                    "error": "Empty face regions extracted", "doc_type": doc_type,
                    "security_level": "FAILED"
                }
            
            # Quality assessment of extracted faces
            face1_quality = self.assess_image_quality(face_img1)
            face2_quality = self.assess_image_quality(face_img2)
            
            min_quality = 0.2
            if face1_quality["overall_quality"] < min_quality or face2_quality["overall_quality"] < min_quality:
                logger.warning(f"‚ö†Ô∏è Face quality too poor - REJECTING")
                return {
                    "verified": False, "distance": 1.0, "threshold": float(doc_threshold),
                    "confidence": 0.0, "time": float(time.time() - start_time),
                    "error": "Face image quality insufficient", "doc_type": doc_type,
                    "security_level": "FAILED",
                    "quality_control": {
                        "face1_quality": face1_quality,
                        "face2_quality": face2_quality,
                        "min_required": min_quality
                    }
                }
            
            # Save faces securely
            img1_id, img2_id = str(uuid.uuid4())[:8], str(uuid.uuid4())[:8]
            cv2.imwrite(str(UPLOADS_DIR / f"{img1_id}.jpg"), face_img1)
            cv2.imwrite(str(UPLOADS_DIR / f"{img2_id}.jpg"), face_img2)
            
            # BANKING-GRADE: 4-method verification for maximum accuracy
            face_img1 = cv2.resize(face_img1, (128, 128))
            face_img2 = cv2.resize(face_img2, (128, 128))
            
            # Method 1: Advanced histogram (30% weight)
            hsv1 = cv2.cvtColor(face_img1, cv2.COLOR_BGR2HSV)
            hsv2 = cv2.cvtColor(face_img2, cv2.COLOR_BGR2HSV)
            hist1 = cv2.calcHist([hsv1], [0, 1], None, [50, 60], [0, 180, 0, 256])
            hist2 = cv2.calcHist([hsv2], [0, 1], None, [50, 60], [0, 180, 0, 256])
            cv2.normalize(hist1, hist1, 0, 1, cv2.NORM_MINMAX)
            cv2.normalize(hist2, hist2, 0, 1, cv2.NORM_MINMAX)
            hist_sim = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
            hist_distance = 1.0 - hist_sim
            
            # Method 2: Structural similarity (30% weight)
            gray1, gray2 = cv2.cvtColor(face_img1, cv2.COLOR_BGR2GRAY), cv2.cvtColor(face_img2, cv2.COLOR_BGR2GRAY)
            try:
                from skimage.metrics import structural_similarity as ssim
                similarity = ssim(gray1, gray2, data_range=255)
                ssim_distance = 1.0 - similarity
            except ImportError:
                blur1 = cv2.GaussianBlur(gray1, (11, 11), 1.5)
                blur2 = cv2.GaussianBlur(gray2, (11, 11), 1.5)
                diff = cv2.absdiff(blur1, blur2)
                mse = np.mean(diff ** 2)
                ssim_distance = mse / (255.0 ** 2)
            
            # Method 3: HOG features (25% weight)
            hog = cv2.HOGDescriptor((128, 128), (16, 16), (8, 8), (8, 8), 9)
            features1 = hog.compute(gray1)
            features2 = hog.compute(gray2)
            hog_distance = cosine_distance(features1, features2)
            
            # Method 4: LBP texture (15% weight)
            def fast_lbp_distance(img1, img2):
                try:
                    kernel = np.array([[-1,-1,-1],[-1,8,-1],[-1,-1,-1]])
                    lbp1 = cv2.filter2D(img1, cv2.CV_8UC1, kernel)
                    lbp2 = cv2.filter2D(img2, cv2.CV_8UC1, kernel)
                    hist1, _ = np.histogram(lbp1.flatten(), bins=32, range=(0, 256))
                    hist2, _ = np.histogram(lbp2.flatten(), bins=32, range=(0, 256))
                    hist1 = hist1.astype(float) / (np.sum(hist1) + 1e-7)
                    hist2 = hist2.astype(float) / (np.sum(hist2) + 1e-7)
                    return 1.0 - np.sum(np.sqrt(hist1 * hist2))
                except:
                    return 0.5
            
            lbp_distance = fast_lbp_distance(gray1, gray2)
            
            # BANKING: Quality-weighted combination
            avg_quality = (face1_quality["overall_quality"] + face2_quality["overall_quality"]) / 2
            quality_adjustment = 1.0 + (avg_quality - 0.5) * 0.1  # ¬±5% adjustment based on quality
            
            combined_distance = (
                hist_distance * 0.30 + 
                ssim_distance * 0.30 + 
                hog_distance * 0.25 +
                lbp_distance * 0.15
            ) * quality_adjustment
            
            # Use document-specific threshold
            verified = bool(combined_distance < doc_threshold)
            
            # Calculate confidence with quality considerations
            if doc_threshold <= 0 or np.isnan(combined_distance) or np.isinf(combined_distance):
                confidence = 0.0
            else:
                base_confidence = (1 - combined_distance / doc_threshold) * 100
                # Quality boost (up to 10%)
                quality_boost = avg_quality * 10
                confidence = float(max(0, min(100, base_confidence + quality_boost)))
            
            # BANKING: Security level based on quality and confidence
            if confidence > 80 and avg_quality > 0.7:
                security_level = "HIGH"
            elif confidence > 65 and avg_quality > 0.5:
                security_level = "MEDIUM"
            else:
                security_level = "LOW"
            
            return {
                "verified": verified,
                "distance": float(combined_distance),
                "threshold": float(doc_threshold),
                "confidence": confidence,
                "id_image": f"/uploads/{img1_id}.jpg",
                "photo_image": f"/uploads/{img2_id}.jpg",
                "time": float(time.time() - start_time),
                "doc_type": doc_type,
                "method": "balanced_banking_grade_4method",
                "security_level": security_level,
                "rotations_applied": (rotation1, rotation2),
                "quality_control": {
                    "face1_quality": face1_quality,
                    "face2_quality": face2_quality,
                    "average_quality": float(avg_quality),
                    "quality_adjustment": float(quality_adjustment),
                    "threshold_source": "config_document_specific"
                },
                "comparisons": {
                    "histogram": float(hist_distance),
                    "structural": float(ssim_distance),
                    "hog_features": float(hog_distance),
                    "texture_lbp": float(lbp_distance)
                },
                "face_detection": {
                    "id_confidence": float(face1["confidence"]),
                    "photo_confidence": float(face2["confidence"])
                }
            }
                
        except Exception as e:
            logger.error(f"Balanced banking verification error: {str(e)}")
            return {
                "verified": False, "error": f"Balanced verification error: {str(e)}",
                "distance": 1.0, "threshold": float(doc_threshold), "confidence": 0.0,
                "time": float(time.time() - start_time), "doc_type": doc_type,
                "security_level": "FAILED", "method": "balanced_error_fallback"
            }